{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401 unused import\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.svm import SVC\n",
    "from bayes_opt import BayesianOptimization\n",
    "from bayes_opt.util import Colours\n",
    "from bayes_opt import UtilityFunction\n",
    "import copy\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    \"\"\"Synthetic binary classification dataset.\"\"\"\n",
    "    data, targets = make_classification(\n",
    "        n_samples=5000,\n",
    "        n_features=100,\n",
    "        n_informative=80,\n",
    "        #n_redundant=2,\n",
    "        n_classes = 5,\n",
    "        #random_state=134985745,\n",
    "    )\n",
    "    return data, targets\n",
    "\n",
    "\n",
    "def svc_cv(expC, expGamma, X, Y):\n",
    "    \"\"\"SVC cross validation.\n",
    "    This function will instantiate a SVC classifier with parameters C and\n",
    "    gamma. Combined with data and targets this will in turn be used to perform\n",
    "    cross validation. The result of cross validation is returned.\n",
    "    Our goal is to find combinations of C and gamma that maximizes the roc_auc\n",
    "    metric.\n",
    "    \"\"\"\n",
    "    \"\"\"Wrapper of SVC cross validation.\n",
    "    Notice how we transform between regular and log scale. While this\n",
    "    is not technically necessary, it greatly improves the performance\n",
    "    of the optimizer.\n",
    "    \"\"\"\n",
    "    C = 10 ** expC\n",
    "    gamma = 10 ** expGamma\n",
    "    estimator = SVC(C=C, gamma=gamma, random_state=2)\n",
    "    cval = cross_val_score(estimator, X, Y, scoring='f1_weighted', cv=4)\n",
    "    return cval.mean()\n",
    "\n",
    "\n",
    "def rfc_cv(n_estimators, min_samples_split, max_features, X, Y):\n",
    "    \"\"\"Random Forest cross validation.\n",
    "    This function will instantiate a random forest classifier with parameters\n",
    "    n_estimators, min_samples_split, and max_features. Combined with data and\n",
    "    targets this will in turn be used to perform cross validation. The result\n",
    "    of cross validation is returned.\n",
    "    Our goal is to find combinations of n_estimators, min_samples_split, and\n",
    "    max_features that minimzes the log loss.\n",
    "    \"\"\"\n",
    "    estimator = RFC(\n",
    "        n_estimators=int(n_estimators),\n",
    "        min_samples_split=int(min_samples_split),\n",
    "        max_features=max_features,\n",
    "        random_state=2\n",
    "    )\n",
    "    cval = cross_val_score(estimator, X, Y,\n",
    "                           scoring='f1_weighted', cv=4)\n",
    "    return cval.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[93m--- Optimizing SVM ---\u001b[0m\n",
      "---------- Optimizing <function svc_cv at 0x7f347f0ab2f0>--------------\n",
      "|   iter    |  target   |   expC    | expGamma  |\n",
      "-------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/yu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/yu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/yu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.06716 \u001b[0m | \u001b[0m-1.002   \u001b[0m | \u001b[0m-2.002   \u001b[0m |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/yu/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "X, Y = get_data()\n",
    "print(Colours.yellow(\"--- Optimizing SVM ---\"))\n",
    "n_iter = 10\n",
    "\n",
    "black_box_funs = [svc_cv, rfc_cv]\n",
    "pbounds_lst = [{\n",
    "                    \"expC\": (-3, 2), \n",
    "                    \"expGamma\": (-4, -1)},\n",
    "               {\n",
    "                    \"n_estimators\": (10, 250),\n",
    "                    \"min_samples_split\": (2, 25),\n",
    "                    \"max_features\": (0.1, 0.999),\n",
    "                }\n",
    "              ]\n",
    "for idx, black_box_fptr in enumerate(black_box_funs):\n",
    "    print(\"---------- Optimizing {}--------------\".format(black_box_fptr))\n",
    "    optimizer = BayesianOptimization(\n",
    "        f=partial(black_box_fptr, X=X, Y=Y),\n",
    "        pbounds=pbounds_lst[idx],\n",
    "        verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "        random_state=65535,\n",
    "    )\n",
    "    utility = UtilityFunction(kind=\"ucb\", kappa=2.5, xi=0.0)\n",
    "    if idx == 0:\n",
    "        optimizer.probe(\n",
    "        params={\"expC\":-1.002, \"expGamma\": -2.002},\n",
    "        lazy=True,\n",
    "        )\n",
    "    else:\n",
    "        optimizer.probe(\n",
    "        params={\"n_estimators\":123, \"min_samples_split\": 21, \"max_features\":0.8888},\n",
    "        lazy=True,\n",
    "        )\n",
    "    optimizer.maximize(init_points=30, n_iter=n_iter)\n",
    "    '''\n",
    "    for _ in range(n_iter):\n",
    "        next_point = optimizer.suggest(utility)\n",
    "        params = copy.copy(next_point)\n",
    "        params.update({\"X\":X, \"Y\":Y})\n",
    "        target = black_box_fptr(**params)\n",
    "        optimizer.register(params=next_point, target=target)    \n",
    "        print(target, next_point)\n",
    "    '''    \n",
    "    print(optimizer.max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
