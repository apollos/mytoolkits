{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Model定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import  os\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import operator\n",
    "from sklearn.svm import  LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import  LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.pipeline import  Pipeline, FeatureUnion\n",
    "from sklearn.svm import  LinearSVC, SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.utils import check_array\n",
    "import pickle\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator, mix_data=False):\n",
    "        self.estimator = estimator\n",
    "        self.mix_data = mix_data\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        if self.mix_data:\n",
    "            X_transformed = np.copy(X)\n",
    "            # add class probabilities/decision_functions as a synthetic feature\n",
    "            if hasattr(self.estimator, 'predict_proba'):\n",
    "                pred = self.estimator.predict_proba(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = np.hstack((pred, X))\n",
    "            elif hasattr(self.estimator, 'decision_function'):\n",
    "                pred = self.estimator.decision_function(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = np.hstack((pred, X))\n",
    "        else:\n",
    "            if hasattr(self.estimator, 'predict_proba'):\n",
    "                pred = self.estimator.predict_proba(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = pred\n",
    "            elif hasattr(self.estimator, 'decision_function'):\n",
    "                pred = self.estimator.decision_function(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = pred\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "        return X_transformed\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "    \n",
    "def train_stacked_model():\n",
    "    allDS = 'merged_table_ac_11.csv'\n",
    "    all_df = pd.read_csv(allDS)\n",
    "    print(\"Start Training!\")\n",
    "    del_feature_name_list = ['MPS03', 'MPS04', 'MPF01', 'LOT_ID_PRODUCT', 'GLASS_ID_PRODUCT', 'label']\n",
    "    # LALEL\n",
    "    label_name_list = ['MPS03', 'MPS04', 'MPF01']\n",
    "    last_label_name = 'label'\n",
    "\n",
    "    num_boost_rounds = 10000\n",
    "    \n",
    "    label_column = all_df[label_name_list[0]]*0\n",
    "    for idx in range(len(label_name_list)):\n",
    "        label_column += all_df[label_name_list[idx]] * (idx+1)\n",
    "    all_df[last_label_name] = label_column\n",
    "    shuffel_df = all_df.sample(frac=1).reset_index(drop=True)\n",
    "    row_count = shuffel_df[last_label_name].count()\n",
    "    train_row = int(row_count*0.8)\n",
    "    \n",
    "    train_df = shuffel_df[:train_row]\n",
    "    test_df = shuffel_df[train_row:]\n",
    "    test_df.to_csv(\"test.csv\", index=False)\n",
    "    train_df.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "    train_data = train_df.drop(del_feature_name_list, axis=1).values\n",
    "    train_label = train_df[last_label_name].values.astype(np.int32)\n",
    "\n",
    "    test_data = test_df.drop(del_feature_name_list, axis=1).values\n",
    "    test_label = test_df[last_label_name].values.astype(np.int32)\n",
    "\n",
    "    xgb_params = {\n",
    "        'eta': 0.005,\n",
    "        'max_depth': 4,\n",
    "        'subsample': 0.95,\n",
    "        #'objective': 'binary:logistic',\n",
    "        'objective': 'multi:softmax',\n",
    "        #'eval_metric': 'error',\n",
    "        'silent': 0,\n",
    "        'n_estimators': num_boost_rounds,\n",
    "        'n_jobs':100\n",
    "    }\n",
    "    xgb_estimator = StackingEstimator(xgb.XGBClassifier(**xgb_params), mix_data=True)\n",
    "\n",
    "    svc1 = StackingEstimator(LinearSVC(penalty='l1', dual=False))\n",
    "    svc2 = StackingEstimator(LinearSVC(penalty='l2', dual=False))\n",
    "    gbt = StackingEstimator(GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1), mix_data=True)\n",
    "    rf = StackingEstimator(RandomForestClassifier(n_estimators=1000, n_jobs=100), mix_data=True)\n",
    "\n",
    "    logistic1 = StackingEstimator(LogisticRegressionCV(cv=4, n_jobs=40,penalty='l1',solver='liblinear'))\n",
    "    logistic2 = StackingEstimator(LogisticRegressionCV(cv=4, n_jobs=40,penalty='l2',solver='liblinear'))\n",
    "\n",
    "    pipline = Pipeline(\n",
    "        [('preprocess',  MinMaxScaler()),\n",
    "         ('level1',  FeatureUnion(transformer_list=[('gbt',gbt),\n",
    "                                  ('pipline',\n",
    "                                   Pipeline([('ica', FastICA(n_components=200)),\n",
    "                                       ('linear_svc', FeatureUnion(transformer_list=[('svc1', svc1),('svc2', svc2),('level2_logistic', logistic1), ('level3_logistic', logistic2)]))]))])),\n",
    "         ('level4_rf', rf),\n",
    "         ('level5_xgb', xgb_estimator)])\n",
    "\n",
    "    pipline.fit(train_data, train_label)\n",
    "    print(\"Start Predict\")\n",
    "    prediction = pipline.predict(test_data)\n",
    "\n",
    "    save_data = {'model': pipline, 'pred':prediction, 'label': test_label}\n",
    "    pickle.dump(save_data, open('train_stacked_model.bin','w'))\n",
    "    print(\"Write result\")\n",
    "    result =pd.DataFrame({'label': test_label, 'pred':prediction[:,1]})\n",
    "    result.to_csv(\"train_stacked_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f4b1665c830, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f4b1665c830, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'train_stacked_model()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2017, 9, 24, 2, 45, 18, 431799, tzinfo=tzlocal()), u'msg_id': u'6B5FE1434F284818AD485F9758359641', u'msg_type': u'execute_request', u'session': u'A4AF15927C5542FA9338E4C3E884275F', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'6B5FE1434F284818AD485F9758359641', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['A4AF15927C5542FA9338E4C3E884275F']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'train_stacked_model()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2017, 9, 24, 2, 45, 18, 431799, tzinfo=tzlocal()), u'msg_id': u'6B5FE1434F284818AD485F9758359641', u'msg_type': u'execute_request', u'session': u'A4AF15927C5542FA9338E4C3E884275F', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'6B5FE1434F284818AD485F9758359641', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['A4AF15927C5542FA9338E4C3E884275F'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'train_stacked_model()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2017, 9, 24, 2, 45, 18, 431799, tzinfo=tzlocal()), u'msg_id': u'6B5FE1434F284818AD485F9758359641', u'msg_type': u'execute_request', u'session': u'A4AF15927C5542FA9338E4C3E884275F', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'6B5FE1434F284818AD485F9758359641', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'train_stacked_model()', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'train_stacked_model()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'train_stacked_model()',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'train_stacked_model()',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'train_stacked_model()', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-19-59266e041c73>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f4acbfd6f10, executi..._before_exec=None error_in_exec=None result=None>)\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n   2827                 code = compiler(mod, cell_name, \"single\")\n-> 2828                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f4acbfe73b0, file \"<ipython-input-19-59266e041c73>\", line 1>\n        result = <ExecutionResult object at 7f4acbfd6f10, executi..._before_exec=None error_in_exec=None result=None>\n   2829                     return True\n   2830 \n   2831             # Flush softspace\n   2832             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f4acbfe73b0, file \"<ipython-input-19-59266e041c73>\", line 1>, result=<ExecutionResult object at 7f4acbfd6f10, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f4acbfe73b0, file \"<ipython-input-19-59266e041c73>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'ClassifierMixin': <class 'sklearn.base.ClassifierMixin'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...se)\\n    test_df.to_csv(\"test.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'ClassifierMixin': <class 'sklearn.base.ClassifierMixin'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...se)\\n    test_df.to_csv(\"test.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/root/workspace/mytoolkits/notebook/stack_ml/<ipython-input-19-59266e041c73> in <module>()\n----> 1 train_stacked_model()\n\n...........................................................................\n/root/workspace/mytoolkits/notebook/stack_ml/<ipython-input-18-ea454056a8a0> in train_stacked_model()\n    122                                    Pipeline([('ica', FastICA(n_components=200)),\n    123                                        ('linear_svc', FeatureUnion(transformer_list=[('svc1', svc1),('svc2', svc2),('level2_logistic', logistic1), ('level3_logistic', logistic2)]))]))])),\n    124          ('level4_rf', rf),\n    125          ('level5_xgb', xgb_estimator)])\n    126 \n--> 127     pipline.fit(train_data, train_label)\n    128     print(\"Start Predict\")\n    129     prediction = pipline.predict(test_data)\n    130 \n    131     save_data = {'model': pipline, 'pred':prediction, 'label': test_label}\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('preprocess',...      subsample=0.95),\n         mix_data=True))]), X=array([[ 0,  0,  0, ...,  0,  1,  0],\n       [ 0...,  0,  0],\n       [ 0,  0,  0, ...,  0,  1,  0]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...     subsample=0.95),\n         mix_data=True))])>\n        X = array([[ 0,  0,  0, ...,  0,  1,  0],\n       [ 0...,  0,  0],\n       [ 0,  0,  0, ...,  0,  1,  0]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('preprocess',...      subsample=0.95),\n         mix_data=True))]), X=array([[ 0,  0,  0, ...,  0,  1,  0],\n       [ 0...,  0,  0],\n       [ 0,  0,  0, ...,  0,  1,  0]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'level1': {}, 'level4_rf': {}, 'level5_xgb': {}, 'preprocess': {}}\n        name = 'level1'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f4acc6efa28>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32)), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32))\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), weight=None, X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...hts=None))]))],\n       transformer_weights=None)>\n        X = array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    741         \"\"\"\n    742         self._validate_transformers()\n    743         result = Parallel(n_jobs=self.n_jobs)(\n    744             delayed(_fit_transform_one)(trans, weight, X, y,\n    745                                         **fit_params)\n--> 746             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...hts=None))]))],\n       transformer_weights=None)>\n    747 \n    748         if not result:\n    749             # All transformers are None\n    750             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object <genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32))\n        kwargs = {}\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32)), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), weight=None, X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ta=False))],\n       transformer_weights=None))])>\n        X = array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    287             Transformed samples\n    288         \"\"\"\n    289         last_step = self._final_estimator\n    290         Xt, fit_params = self._fit(X, y, **fit_params)\n    291         if hasattr(last_step, 'fit_transform'):\n--> 292             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method FeatureUnion.fit_transform of Feat..._data=False))],\n       transformer_weights=None)>\n        Xt = array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    293         elif last_step is None:\n    294             return Xt\n    295         else:\n    296             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...x_data=False))],\n       transformer_weights=None), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    741         \"\"\"\n    742         self._validate_transformers()\n    743         result = Parallel(n_jobs=self.n_jobs)(\n    744             delayed(_fit_transform_one)(trans, weight, X, y,\n    745                                         **fit_params)\n--> 746             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion..._data=False))],\n       transformer_weights=None)>\n    747 \n    748         if not result:\n    749             # All transformers are None\n    750             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object <genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), None, array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32))\n        kwargs = {}\n        self.items = [(<function _fit_transform_one>, (StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), None, array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32)), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), weight=None, X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method StackingEstimator.fit_transform of...\n           verbose=0),\n         mix_data=False)>\n        X = array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.py in fit_transform(self=StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    516         if y is None:\n    517             # fit method of arity 1 (unsupervised transformation)\n    518             return self.fit(X, **fit_params).transform(X)\n    519         else:\n    520             # fit method of arity 2 (supervised transformation)\n--> 521             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StackingEstimator.fit of StackingE...\n           verbose=0),\n         mix_data=False)>\n        X = array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params.transform = undefined\n    522 \n    523 \n    524 class DensityMixin(object):\n    525     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/root/workspace/mytoolkits/notebook/stack_ml/<ipython-input-18-ea454056a8a0> in fit(self=StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n     25     def __init__(self, estimator, mix_data=False):\n     26         self.estimator = estimator\n     27         self.mix_data = mix_data\n     28 \n     29     def fit(self, X, y=None, **fit_params):\n---> 30         self.estimator.fit(X, y, **fit_params)\n     31         return self\n     32 \n     33     def transform(self, X):\n     34         X = check_array(X)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegressionCV(Cs=10, class_weight=None, c...er='liblinear', tol=0.0001,\n           verbose=0), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0]), sample_weight=None)\n   1682                       intercept_scaling=self.intercept_scaling,\n   1683                       random_state=self.random_state,\n   1684                       max_squared_sum=max_squared_sum,\n   1685                       sample_weight=sample_weight\n   1686                       )\n-> 1687             for label in iter_encoded_labels\n        iter_encoded_labels = array([0, 1, 2, 3, 4, 5, 6])\n   1688             for train, test in folds)\n   1689 \n   1690         if self.multi_class == 'multinomial':\n   1691             multi_coefs_paths, Cs, multi_scores, n_iter_ = zip(*fold_coefs_)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=40), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=40)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Sep 24 02:49:45 2017\nPID: 1801                                    Python 2.7.12: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _log_reg_scoring_path>\n        args = (memmap([[  6.10351562e-05,   6.48498535e-05,   4...229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0]), array([ 884, 1550, 1822, ..., 8383, 8384, 8385]), array([   0,    1,    2, ..., 2200, 2202, 2409]))\n        kwargs = {'Cs': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'max_iter': 100, 'max_squared_sum': None, 'multi_class': 'ovr', 'penalty': 'l1', 'pos_class': 6, ...}\n        self.items = [(<function _log_reg_scoring_path>, (memmap([[  6.10351562e-05,   6.48498535e-05,   4...229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0]), array([ 884, 1550, 1822, ..., 8383, 8384, 8385]), array([   0,    1,    2, ..., 2200, 2202, 2409])), {'Cs': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'max_iter': 100, 'max_squared_sum': None, 'multi_class': 'ovr', 'penalty': 'l1', 'pos_class': 6, ...})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py in _log_reg_scoring_path(X=memmap([[  6.10351562e-05,   6.48498535e-05,   4...229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0]), train=array([ 884, 1550, 1822, ..., 8383, 8384, 8385]), test=array([   0,    1,    2, ..., 2200, 2202, 2409]), pos_class=6, Cs=10, scoring=None, fit_intercept=True, max_iter=100, tol=0.0001, class_weight=None, verbose=0, solver='liblinear', penalty='l1', dual=False, intercept_scaling=1.0, multi_class='ovr', random_state=None, max_squared_sum=None, sample_weight=None)\n    918         solver=solver, max_iter=max_iter, class_weight=class_weight,\n    919         pos_class=pos_class, multi_class=multi_class,\n    920         tol=tol, verbose=verbose, dual=dual, penalty=penalty,\n    921         intercept_scaling=intercept_scaling, random_state=random_state,\n    922         check_input=False, max_squared_sum=max_squared_sum,\n--> 923         sample_weight=sample_weight)\n        sample_weight = None\n    924 \n    925     log_reg = LogisticRegression(fit_intercept=fit_intercept)\n    926 \n    927     # The score method of Logistic Regression has a classes_ attribute.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py in logistic_regression_path(X=array([[ 0.00241089, -0.00372887, -0.00018311, .... -0.00485229,\n         0.00115967,  0.00086975]]), y=array([4, 5, 5, ..., 0, 2, 0]), pos_class=6, Cs=array([  1.00000000e-04,   7.74263683e-04,   5.9...e+02,   1.29154967e+03,\n         1.00000000e+04]), fit_intercept=True, max_iter=100, tol=0.0001, verbose=0, solver='liblinear', coef=None, class_weight=None, dual=False, penalty='l1', intercept_scaling=1.0, multi_class='ovr', random_state=<mtrand.RandomState object>, check_input=False, max_squared_sum=None, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    727                                      maxiter=max_iter, tol=tol)\n    728         elif solver == 'liblinear':\n    729             coef_, intercept_, n_iter_i, = _fit_liblinear(\n    730                 X, target, C, fit_intercept, intercept_scaling, None,\n    731                 penalty, dual, verbose, max_iter, tol, random_state,\n--> 732                 sample_weight=sample_weight)\n        sample_weight = array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n    733             if fit_intercept:\n    734                 w0 = np.concatenate([coef_.ravel(), intercept_])\n    735             else:\n    736                 w0 = coef_.ravel()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in _fit_liblinear(X=array([[ 0.00241089, -0.00372887, -0.00018311, .... -0.00485229,\n         0.00115967,  0.00086975]]), y=array([-1., -1., -1., ..., -1., -1., -1.]), C=0.0001, fit_intercept=True, intercept_scaling=1.0, class_weight=None, penalty='l1', dual=False, verbose=0, max_iter=100, tol=0.0001, random_state=<mtrand.RandomState object>, multi_class='ovr', loss='logistic_regression', epsilon=0.1, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    848         y_ind = enc.fit_transform(y)\n    849         classes_ = enc.classes_\n    850         if len(classes_) < 2:\n    851             raise ValueError(\"This solver needs samples of at least 2 classes\"\n    852                              \" in the data, but the data contains only one\"\n--> 853                              \" class: %r\" % classes_[0])\n        classes_ = array([-1.])\n    854 \n    855         class_weight_ = compute_class_weight(class_weight, classes_, y)\n    856     else:\n    857         class_weight_ = np.empty(0, dtype=np.float64)\n\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: -1.0\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-59266e041c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_stacked_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-ea454056a8a0>\u001b[0m in \u001b[0;36mtrain_stacked_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m          ('level5_xgb', xgb_estimator)])\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mpipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Start Predict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \"\"\"\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    221\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    587\u001b[0m                        **fit_params):\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    744\u001b[0m             delayed(_fit_transform_one)(trans, weight, X, y,\n\u001b[1;32m    745\u001b[0m                                         **fit_params)\n\u001b[0;32m--> 746\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    587\u001b[0m                        **fit_params):\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlast_step\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    744\u001b[0m             delayed(_fit_transform_one)(trans, weight, X, y,\n\u001b[1;32m    745\u001b[0m                                         **fit_params)\n\u001b[0;32m--> 746\u001b[0;31m             for name, trans, weight in self._iter())\n\u001b[0m\u001b[1;32m    747\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    587\u001b[0m                        **fit_params):\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-ea454056a8a0>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1685\u001b[0m                       \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1686\u001b[0m                       )\n\u001b[0;32m-> 1687\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1688\u001b[0m             for train, test in folds)\n\u001b[1;32m   1689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/lib/python2.7/runpy.py in _run_code(code=<code object <module> at 0x7f4b1665c830, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname='/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0x7f4b1665c830, file \"/...2.7/dist-packages/ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': '/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'train_stacked_model()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2017, 9, 24, 2, 45, 18, 431799, tzinfo=tzlocal()), u'msg_id': u'6B5FE1434F284818AD485F9758359641', u'msg_type': u'execute_request', u'session': u'A4AF15927C5542FA9338E4C3E884275F', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'6B5FE1434F284818AD485F9758359641', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['A4AF15927C5542FA9338E4C3E884275F']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u'train_stacked_model()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2017, 9, 24, 2, 45, 18, 431799, tzinfo=tzlocal()), u'msg_id': u'6B5FE1434F284818AD485F9758359641', u'msg_type': u'execute_request', u'session': u'A4AF15927C5542FA9338E4C3E884275F', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'6B5FE1434F284818AD485F9758359641', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['A4AF15927C5542FA9338E4C3E884275F'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u'train_stacked_model()', u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {u'date': datetime.datetime(2017, 9, 24, 2, 45, 18, 431799, tzinfo=tzlocal()), u'msg_id': u'6B5FE1434F284818AD485F9758359641', u'msg_type': u'execute_request', u'session': u'A4AF15927C5542FA9338E4C3E884275F', u'username': u'username', u'version': u'5.2'}, 'metadata': {}, 'msg_id': u'6B5FE1434F284818AD485F9758359641', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u'train_stacked_model()', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u'train_stacked_model()'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u'train_stacked_model()',), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u'train_stacked_model()',)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u'train_stacked_model()', store_history=True, silent=False, shell_futures=True)\n   2713                 self.displayhook.exec_result = result\n   2714 \n   2715                 # Execute the user code\n   2716                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2717                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2718                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2719                 \n   2720                 self.last_execution_succeeded = not has_raised\n   2721 \n   2722                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-19-59266e041c73>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 7f4acbfd6f10, executi..._before_exec=None error_in_exec=None result=None>)\n   2823                     return True\n   2824 \n   2825             for i, node in enumerate(to_run_interactive):\n   2826                 mod = ast.Interactive([node])\n   2827                 code = compiler(mod, cell_name, \"single\")\n-> 2828                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f4acbfe73b0, file \"<ipython-input-19-59266e041c73>\", line 1>\n        result = <ExecutionResult object at 7f4acbfd6f10, executi..._before_exec=None error_in_exec=None result=None>\n   2829                     return True\n   2830 \n   2831             # Flush softspace\n   2832             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f4acbfe73b0, file \"<ipython-input-19-59266e041c73>\", line 1>, result=<ExecutionResult object at 7f4acbfd6f10, executi..._before_exec=None error_in_exec=None result=None>)\n   2877         outflag = 1  # happens in more places, so it's easier as default\n   2878         try:\n   2879             try:\n   2880                 self.hooks.pre_run_code_hook()\n   2881                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2882                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f4acbfe73b0, file \"<ipython-input-19-59266e041c73>\", line 1>\n        self.user_global_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'ClassifierMixin': <class 'sklearn.base.ClassifierMixin'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...se)\\n    test_df.to_csv(\"test.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n        self.user_ns = {'BaseEstimator': <class 'sklearn.base.BaseEstimator'>, 'ClassifierMixin': <class 'sklearn.base.ClassifierMixin'>, 'FastICA': <class 'sklearn.decomposition.fastica_.FastICA'>, 'FeatureUnion': <class 'sklearn.pipeline.FeatureUnion'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...se)\\n    test_df.to_csv(\"test.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()', u'import argparse\\nimport numpy as np\\nimport pi...t.to_csv(\"train_stacked_model.csv\", index=False)', u'train_stacked_model()'], 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'MinMaxScaler': <class 'sklearn.preprocessing.data.MinMaxScaler'>, ...}\n   2883             finally:\n   2884                 # Reset our crash handler in place\n   2885                 sys.excepthook = old_excepthook\n   2886         except SystemExit as e:\n\n...........................................................................\n/root/workspace/mytoolkits/notebook/stack_ml/<ipython-input-19-59266e041c73> in <module>()\n----> 1 train_stacked_model()\n\n...........................................................................\n/root/workspace/mytoolkits/notebook/stack_ml/<ipython-input-18-ea454056a8a0> in train_stacked_model()\n    122                                    Pipeline([('ica', FastICA(n_components=200)),\n    123                                        ('linear_svc', FeatureUnion(transformer_list=[('svc1', svc1),('svc2', svc2),('level2_logistic', logistic1), ('level3_logistic', logistic2)]))]))])),\n    124          ('level4_rf', rf),\n    125          ('level5_xgb', xgb_estimator)])\n    126 \n--> 127     pipline.fit(train_data, train_label)\n    128     print(\"Start Predict\")\n    129     prediction = pipline.predict(test_data)\n    130 \n    131     save_data = {'model': pipline, 'pred':prediction, 'label': test_label}\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit(self=Pipeline(memory=None,\n     steps=[('preprocess',...      subsample=0.95),\n         mix_data=True))]), X=array([[ 0,  0,  0, ...,  0,  1,  0],\n       [ 0...,  0,  0],\n       [ 0,  0,  0, ...,  0,  1,  0]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    252         Returns\n    253         -------\n    254         self : Pipeline\n    255             This estimator\n    256         \"\"\"\n--> 257         Xt, fit_params = self._fit(X, y, **fit_params)\n        Xt = undefined\n        fit_params = {}\n        self._fit = <bound method Pipeline._fit of Pipeline(memory=N...     subsample=0.95),\n         mix_data=True))])>\n        X = array([[ 0,  0,  0, ...,  0,  1,  0],\n       [ 0...,  0,  0],\n       [ 0,  0,  0, ...,  0,  1,  0]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n    258         if self._final_estimator is not None:\n    259             self._final_estimator.fit(Xt, y, **fit_params)\n    260         return self\n    261 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit(self=Pipeline(memory=None,\n     steps=[('preprocess',...      subsample=0.95),\n         mix_data=True))]), X=array([[ 0,  0,  0, ...,  0,  1,  0],\n       [ 0...,  0,  0],\n       [ 0,  0,  0, ...,  0,  1,  0]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    217                 else:\n    218                     cloned_transformer = clone(transformer)\n    219                 # Fit or load from cache the current transfomer\n    220                 Xt, fitted_transformer = fit_transform_one_cached(\n    221                     cloned_transformer, None, Xt, y,\n--> 222                     **fit_params_steps[name])\n        fit_params_steps = {'level1': {}, 'level4_rf': {}, 'level5_xgb': {}, 'preprocess': {}}\n        name = 'level1'\n    223                 # Replace the transformer of the step with the fitted\n    224                 # transformer. This is necessary when loading the transformer\n    225                 # from the cache.\n    226                 self.steps[step_idx] = (name, fitted_transformer)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/memory.py in __call__(self=NotMemorizedFunc(func=<function _fit_transform_one at 0x7f4acc6efa28>), *args=(FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32)), **kwargs={})\n    357     # Should be a light as possible (for speed)\n    358     def __init__(self, func):\n    359         self.func = func\n    360 \n    361     def __call__(self, *args, **kwargs):\n--> 362         return self.func(*args, **kwargs)\n        self.func = <function _fit_transform_one>\n        args = (FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32))\n        kwargs = {}\n    363 \n    364     def call_and_shelve(self, *args, **kwargs):\n    365         return NotMemorizedResult(self.func(*args, **kwargs))\n    366 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), weight=None, X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method FeatureUnion.fit_transform of Feat...hts=None))]))],\n       transformer_weights=None)>\n        X = array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...ghts=None))]))],\n       transformer_weights=None), X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    741         \"\"\"\n    742         self._validate_transformers()\n    743         result = Parallel(n_jobs=self.n_jobs)(\n    744             delayed(_fit_transform_one)(trans, weight, X, y,\n    745                                         **fit_params)\n--> 746             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion...hts=None))]))],\n       transformer_weights=None)>\n    747 \n    748         if not result:\n    749             # All transformers are None\n    750             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object <genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32))\n        kwargs = {}\n        self.items = [(<function _fit_transform_one>, (Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), None, array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32)), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), weight=None, X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method Pipeline.fit_transform of Pipeline...ta=False))],\n       transformer_weights=None))])>\n        X = array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit_transform(self=Pipeline(memory=None,\n     steps=[('ica', FastIC...ata=False))],\n       transformer_weights=None))]), X=array([[ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]...      [ 0. ,  0. ,  0. , ...,  0.5,  1. ,  0.5]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    287             Transformed samples\n    288         \"\"\"\n    289         last_step = self._final_estimator\n    290         Xt, fit_params = self._fit(X, y, **fit_params)\n    291         if hasattr(last_step, 'fit_transform'):\n--> 292             return last_step.fit_transform(Xt, y, **fit_params)\n        last_step.fit_transform = <bound method FeatureUnion.fit_transform of Feat..._data=False))],\n       transformer_weights=None)>\n        Xt = array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    293         elif last_step is None:\n    294             return Xt\n    295         else:\n    296             return last_step.fit(Xt, y, **fit_params).transform(Xt)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in fit_transform(self=FeatureUnion(n_jobs=1,\n       transformer_list=[...x_data=False))],\n       transformer_weights=None), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    741         \"\"\"\n    742         self._validate_transformers()\n    743         result = Parallel(n_jobs=self.n_jobs)(\n    744             delayed(_fit_transform_one)(trans, weight, X, y,\n    745                                         **fit_params)\n--> 746             for name, trans, weight in self._iter())\n        self._iter = <bound method FeatureUnion._iter of FeatureUnion..._data=False))],\n       transformer_weights=None)>\n    747 \n    748         if not result:\n    749             # All transformers are None\n    750             return np.zeros((X.shape[0], 0))\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=1), iterable=<generator object <genexpr>>)\n    774         self.n_completed_tasks = 0\n    775         try:\n    776             # Only set self._iterating to True if at least a batch\n    777             # was dispatched. In particular this covers the edge\n    778             # case of Parallel used with an exhausted iterator.\n--> 779             while self.dispatch_one_batch(iterator):\n        self.dispatch_one_batch = <bound method Parallel.dispatch_one_batch of Parallel(n_jobs=1)>\n        iterator = <generator object <genexpr>>\n    780                 self._iterating = True\n    781             else:\n    782                 self._iterating = False\n    783 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in dispatch_one_batch(self=Parallel(n_jobs=1), iterator=<generator object <genexpr>>)\n    620             tasks = BatchedCalls(itertools.islice(iterator, batch_size))\n    621             if len(tasks) == 0:\n    622                 # No more tasks available in the iterator: tell caller to stop.\n    623                 return False\n    624             else:\n--> 625                 self._dispatch(tasks)\n        self._dispatch = <bound method Parallel._dispatch of Parallel(n_jobs=1)>\n        tasks = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    626                 return True\n    627 \n    628     def _print(self, msg, msg_args):\n    629         \"\"\"Display the message on stout or stderr depending on verbosity\"\"\"\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in _dispatch(self=Parallel(n_jobs=1), batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    583         self.n_dispatched_tasks += len(batch)\n    584         self.n_dispatched_batches += 1\n    585 \n    586         dispatch_timestamp = time.time()\n    587         cb = BatchCompletionCallBack(dispatch_timestamp, len(batch), self)\n--> 588         job = self._backend.apply_async(batch, callback=cb)\n        job = undefined\n        self._backend.apply_async = <bound method SequentialBackend.apply_async of <...lib._parallel_backends.SequentialBackend object>>\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n        cb = <sklearn.externals.joblib.parallel.BatchCompletionCallBack object>\n    589         self._jobs.append(job)\n    590 \n    591     def dispatch_next(self):\n    592         \"\"\"Dispatch more data for parallel processing\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in apply_async(self=<sklearn.externals.joblib._parallel_backends.SequentialBackend object>, func=<sklearn.externals.joblib.parallel.BatchedCalls object>, callback=<sklearn.externals.joblib.parallel.BatchCompletionCallBack object>)\n    106             raise ValueError('n_jobs == 0 in Parallel has no meaning')\n    107         return 1\n    108 \n    109     def apply_async(self, func, callback=None):\n    110         \"\"\"Schedule a func to be run\"\"\"\n--> 111         result = ImmediateResult(func)\n        result = undefined\n        func = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    112         if callback:\n    113             callback(result)\n    114         return result\n    115 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/_parallel_backends.py in __init__(self=<sklearn.externals.joblib._parallel_backends.ImmediateResult object>, batch=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    327 \n    328 class ImmediateResult(object):\n    329     def __init__(self, batch):\n    330         # Don't delay the application, to avoid keeping the input\n    331         # arguments in memory\n--> 332         self.results = batch()\n        self.results = undefined\n        batch = <sklearn.externals.joblib.parallel.BatchedCalls object>\n    333 \n    334     def get(self):\n    335         return self.results\n    336 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_transform_one>\n        args = (StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), None, array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32))\n        kwargs = {}\n        self.items = [(<function _fit_transform_one>, (StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), None, array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0], dtype=int32)), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/pipeline.py in _fit_transform_one(transformer=StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), weight=None, X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    584 \n    585 \n    586 def _fit_transform_one(transformer, weight, X, y,\n    587                        **fit_params):\n    588     if hasattr(transformer, 'fit_transform'):\n--> 589         res = transformer.fit_transform(X, y, **fit_params)\n        res = undefined\n        transformer.fit_transform = <bound method StackingEstimator.fit_transform of...\n           verbose=0),\n         mix_data=False)>\n        X = array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params = {}\n    590     else:\n    591         res = transformer.fit(X, y, **fit_params).transform(X)\n    592     # if we have a weight for this transformer, multiply output\n    593     if weight is None:\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/base.py in fit_transform(self=StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n    516         if y is None:\n    517             # fit method of arity 1 (unsupervised transformation)\n    518             return self.fit(X, **fit_params).transform(X)\n    519         else:\n    520             # fit method of arity 2 (supervised transformation)\n--> 521             return self.fit(X, y, **fit_params).transform(X)\n        self.fit = <bound method StackingEstimator.fit of StackingE...\n           verbose=0),\n         mix_data=False)>\n        X = array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]])\n        y = array([0, 2, 0, ..., 0, 2, 0], dtype=int32)\n        fit_params.transform = undefined\n    522 \n    523 \n    524 class DensityMixin(object):\n    525     \"\"\"Mixin class for all density estimators in scikit-learn.\"\"\"\n\n...........................................................................\n/root/workspace/mytoolkits/notebook/stack_ml/<ipython-input-18-ea454056a8a0> in fit(self=StackingEstimator(estimator=LogisticRegressionCV...,\n           verbose=0),\n         mix_data=False), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0], dtype=int32), **fit_params={})\n     25     def __init__(self, estimator, mix_data=False):\n     26         self.estimator = estimator\n     27         self.mix_data = mix_data\n     28 \n     29     def fit(self, X, y=None, **fit_params):\n---> 30         self.estimator.fit(X, y, **fit_params)\n     31         return self\n     32 \n     33     def transform(self, X):\n     34         X = check_array(X)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py in fit(self=LogisticRegressionCV(Cs=10, class_weight=None, c...er='liblinear', tol=0.0001,\n           verbose=0), X=array([[  6.10351562e-05,   6.48498535e-05,   4....229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0]), sample_weight=None)\n   1682                       intercept_scaling=self.intercept_scaling,\n   1683                       random_state=self.random_state,\n   1684                       max_squared_sum=max_squared_sum,\n   1685                       sample_weight=sample_weight\n   1686                       )\n-> 1687             for label in iter_encoded_labels\n        iter_encoded_labels = array([0, 1, 2, 3, 4, 5, 6])\n   1688             for train, test in folds)\n   1689 \n   1690         if self.multi_class == 'multinomial':\n   1691             multi_coefs_paths, Cs, multi_scores, n_iter_ = zip(*fold_coefs_)\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=40), iterable=<generator object <genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=40)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Sun Sep 24 02:49:45 2017\nPID: 1801                                    Python 2.7.12: /usr/bin/python\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _log_reg_scoring_path>\n        args = (memmap([[  6.10351562e-05,   6.48498535e-05,   4...229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0]), array([ 884, 1550, 1822, ..., 8383, 8384, 8385]), array([   0,    1,    2, ..., 2200, 2202, 2409]))\n        kwargs = {'Cs': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'max_iter': 100, 'max_squared_sum': None, 'multi_class': 'ovr', 'penalty': 'l1', 'pos_class': 6, ...}\n        self.items = [(<function _log_reg_scoring_path>, (memmap([[  6.10351562e-05,   6.48498535e-05,   4...229492e-03,   1.15966797e-03,   8.69750977e-04]]), array([0, 2, 0, ..., 0, 2, 0]), array([ 884, 1550, 1822, ..., 8383, 8384, 8385]), array([   0,    1,    2, ..., 2200, 2202, 2409])), {'Cs': 10, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1.0, 'max_iter': 100, 'max_squared_sum': None, 'multi_class': 'ovr', 'penalty': 'l1', 'pos_class': 6, ...})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py in _log_reg_scoring_path(X=memmap([[  6.10351562e-05,   6.48498535e-05,   4...229492e-03,   1.15966797e-03,   8.69750977e-04]]), y=array([0, 2, 0, ..., 0, 2, 0]), train=array([ 884, 1550, 1822, ..., 8383, 8384, 8385]), test=array([   0,    1,    2, ..., 2200, 2202, 2409]), pos_class=6, Cs=10, scoring=None, fit_intercept=True, max_iter=100, tol=0.0001, class_weight=None, verbose=0, solver='liblinear', penalty='l1', dual=False, intercept_scaling=1.0, multi_class='ovr', random_state=None, max_squared_sum=None, sample_weight=None)\n    918         solver=solver, max_iter=max_iter, class_weight=class_weight,\n    919         pos_class=pos_class, multi_class=multi_class,\n    920         tol=tol, verbose=verbose, dual=dual, penalty=penalty,\n    921         intercept_scaling=intercept_scaling, random_state=random_state,\n    922         check_input=False, max_squared_sum=max_squared_sum,\n--> 923         sample_weight=sample_weight)\n        sample_weight = None\n    924 \n    925     log_reg = LogisticRegression(fit_intercept=fit_intercept)\n    926 \n    927     # The score method of Logistic Regression has a classes_ attribute.\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/linear_model/logistic.py in logistic_regression_path(X=array([[ 0.00241089, -0.00372887, -0.00018311, .... -0.00485229,\n         0.00115967,  0.00086975]]), y=array([4, 5, 5, ..., 0, 2, 0]), pos_class=6, Cs=array([  1.00000000e-04,   7.74263683e-04,   5.9...e+02,   1.29154967e+03,\n         1.00000000e+04]), fit_intercept=True, max_iter=100, tol=0.0001, verbose=0, solver='liblinear', coef=None, class_weight=None, dual=False, penalty='l1', intercept_scaling=1.0, multi_class='ovr', random_state=<mtrand.RandomState object>, check_input=False, max_squared_sum=None, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    727                                      maxiter=max_iter, tol=tol)\n    728         elif solver == 'liblinear':\n    729             coef_, intercept_, n_iter_i, = _fit_liblinear(\n    730                 X, target, C, fit_intercept, intercept_scaling, None,\n    731                 penalty, dual, verbose, max_iter, tol, random_state,\n--> 732                 sample_weight=sample_weight)\n        sample_weight = array([ 1.,  1.,  1., ...,  1.,  1.,  1.])\n    733             if fit_intercept:\n    734                 w0 = np.concatenate([coef_.ravel(), intercept_])\n    735             else:\n    736                 w0 = coef_.ravel()\n\n...........................................................................\n/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.py in _fit_liblinear(X=array([[ 0.00241089, -0.00372887, -0.00018311, .... -0.00485229,\n         0.00115967,  0.00086975]]), y=array([-1., -1., -1., ..., -1., -1., -1.]), C=0.0001, fit_intercept=True, intercept_scaling=1.0, class_weight=None, penalty='l1', dual=False, verbose=0, max_iter=100, tol=0.0001, random_state=<mtrand.RandomState object>, multi_class='ovr', loss='logistic_regression', epsilon=0.1, sample_weight=array([ 1.,  1.,  1., ...,  1.,  1.,  1.]))\n    848         y_ind = enc.fit_transform(y)\n    849         classes_ = enc.classes_\n    850         if len(classes_) < 2:\n    851             raise ValueError(\"This solver needs samples of at least 2 classes\"\n    852                              \" in the data, but the data contains only one\"\n--> 853                              \" class: %r\" % classes_[0])\n        classes_ = array([-1.])\n    854 \n    855         class_weight_ = compute_class_weight(class_weight, classes_, y)\n    856     else:\n    857         class_weight_ = np.empty(0, dtype=np.float64)\n\nValueError: This solver needs samples of at least 2 classes in the data, but the data contains only one class: -1.0\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "train_stacked_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
