{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacked Model定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import pickle\n",
    "import random\n",
    "import pandas as pd\n",
    "import  os\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import operator\n",
    "from sklearn.svm import  LinearSVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import  LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.pipeline import  Pipeline, FeatureUnion\n",
    "from sklearn.svm import  LinearSVC, SVC\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin\n",
    "from sklearn.utils import check_array\n",
    "import pickle\n",
    "from sklearn.preprocessing import  MinMaxScaler\n",
    "from sklearn.decomposition import FastICA\n",
    "\n",
    "class StackingEstimator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, estimator, mix_data=False):\n",
    "        self.estimator = estimator\n",
    "        self.mix_data = mix_data\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = check_array(X)\n",
    "        if self.mix_data:\n",
    "            X_transformed = np.copy(X)\n",
    "            # add class probabilities/decision_functions as a synthetic feature\n",
    "            if hasattr(self.estimator, 'predict_proba'):\n",
    "                pred = self.estimator.predict_proba(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = np.hstack((pred, X))\n",
    "            elif hasattr(self.estimator, 'decision_function'):\n",
    "                pred = self.estimator.decision_function(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = np.hstack((pred, X))\n",
    "        else:\n",
    "            if hasattr(self.estimator, 'predict_proba'):\n",
    "                pred = self.estimator.predict_proba(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = pred\n",
    "            elif hasattr(self.estimator, 'decision_function'):\n",
    "                pred = self.estimator.decision_function(X)\n",
    "                if len(pred.shape) == 1:\n",
    "                    pred = pred.reshape(-1, 1)\n",
    "                X_transformed = pred\n",
    "        # add class prodiction as a synthetic feature\n",
    "        X_transformed = np.hstack((np.reshape(self.estimator.predict(X), (-1, 1)), X_transformed))\n",
    "        return X_transformed\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "    \n",
    "def train_stacked_model():\n",
    "    allDS = 'merged_table_ac_11.csv'\n",
    "    all_df = pd.read_csv(allDS)\n",
    "    print(\"Start Training!\")\n",
    "    del_feature_name_list = ['MPS03', 'MPS04', 'MPF01', 'LOT_ID_PRODUCT', 'GLASS_ID_PRODUCT', 'label']\n",
    "    # LALEL\n",
    "    label_name_list = ['MPS03', 'MPS04', 'MPF01']\n",
    "    last_label_name = 'label'\n",
    "\n",
    "    num_boost_rounds = 10000\n",
    "    \n",
    "    label_column = all_df[label_name_list[0]]*0\n",
    "    for idx in range(len(label_name_list)):\n",
    "        label_column += all_df[label_name_list[idx]] * (idx+1)\n",
    "    all_df[last_label_name] = label_column\n",
    "    shuffel_df = all_df.sample(frac=1).reset_index(drop=True)\n",
    "    row_count = shuffel_df[last_label_name].count()\n",
    "    train_row = int(row_count*0.8)\n",
    "    \n",
    "    train_df = shuffel_df[:train_row]\n",
    "    test_df = shuffel_df[train_row:]\n",
    "    test_df.to_csv(\"test.csv\", index=False)\n",
    "    train_df.to_csv(\"train.csv\", index=False)\n",
    "\n",
    "    train_data = train_df.drop(del_feature_name_list, axis=1).values\n",
    "    train_label = train_df[last_label_name].values.astype(np.int32)\n",
    "\n",
    "    test_data = test_df.drop(del_feature_name_list, axis=1).values\n",
    "    test_label = test_df[last_label_name].values.astype(np.int32)\n",
    "\n",
    "    xgb_params = {\n",
    "        'eta': 0.005,\n",
    "        'max_depth': 4,\n",
    "        'subsample': 0.95,\n",
    "        #'objective': 'binary:logistic',\n",
    "        'objective': 'multi:softmax',\n",
    "        #'eval_metric': 'error',\n",
    "        'silent': 0,\n",
    "        'n_estimators': num_boost_rounds,\n",
    "        'n_jobs':100\n",
    "    }\n",
    "    xgb_estimator = StackingEstimator(xgb.XGBClassifier(**xgb_params), mix_data=True)\n",
    "\n",
    "    svc1 = StackingEstimator(LinearSVC(penalty='l1', dual=False))\n",
    "    svc2 = StackingEstimator(LinearSVC(penalty='l2', dual=False))\n",
    "    gbt = StackingEstimator(GradientBoostingClassifier(n_estimators=1000, learning_rate=0.1), mix_data=True)\n",
    "    rf = StackingEstimator(RandomForestClassifier(n_estimators=1000, n_jobs=100), mix_data=True)\n",
    "\n",
    "    logistic1 = StackingEstimator(LogisticRegressionCV(cv=4, n_jobs=40,penalty='l1',solver='liblinear'))\n",
    "    logistic2 = StackingEstimator(LogisticRegressionCV(cv=4, n_jobs=40,penalty='l2',solver='liblinear'))\n",
    "\n",
    "    pipline = Pipeline(\n",
    "        [('preprocess',  MinMaxScaler()),\n",
    "         ('level1',  FeatureUnion(transformer_list=[('gbt',gbt),\n",
    "                                  ('pipline',\n",
    "                                   Pipeline([('ica', FastICA(n_components=200)),\n",
    "                                       ('linear_svc', FeatureUnion(transformer_list=[('svc1', svc1),('svc2', svc2),('level2_logistic', logistic1), ('level3_logistic', logistic2)]))]))])),\n",
    "         ('level4_rf', rf),\n",
    "         ('level5_xgb', xgb_estimator)])\n",
    "\n",
    "    pipline.fit(train_data, train_label)\n",
    "    print(\"Start Predict\")\n",
    "    prediction = pipline.predict(test_data)\n",
    "\n",
    "    save_data = {'model': pipline, 'pred':prediction, 'label': test_label}\n",
    "    pickle.dump(save_data, open('train_stacked_model.bin','w'))\n",
    "    print(\"Write result\")\n",
    "    result =pd.DataFrame({'label': test_label, 'pred':prediction[:,1]})\n",
    "    result.to_csv(\"train_stacked_model.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "labels [None] not contained in axis",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-59266e041c73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_stacked_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-e5b5584890a2>\u001b[0m in \u001b[0;36mtrain_stacked_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdel_feature_name_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_label_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0mtrain_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlast_label_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, level, inplace, errors)\u001b[0m\n\u001b[1;32m   2159\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2161\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2162\u001b[0m             \u001b[0mdropped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2163\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pandas/core/indexes/base.pyc\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   3622\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'ignore'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m                 raise ValueError('labels %s not contained in axis' %\n\u001b[0;32m-> 3624\u001b[0;31m                                  labels[mask])\n\u001b[0m\u001b[1;32m   3625\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: labels [None] not contained in axis"
     ]
    }
   ],
   "source": [
    "train_stacked_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
